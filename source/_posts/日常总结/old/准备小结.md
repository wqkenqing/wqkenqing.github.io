---
title: 准备小结
tags: 小结
---
# 准备小结

<!-- more -->
## hdfs存储机制是怎样的?
client端发送写文件请求，namenode检查文件是否存在，如果已存在，直接返回错误信息，否则，发送给client一些可用namenode节点
client将文件分块，并行存储到不同节点上datanode上，发送完成后，client同时发送信息给namenode和datanode
namenode收到的client信息后，发送确信信息给datanode
datanode同时收到namenode和datanode的确认信息后，提交写操作。
## hadoop中combiner的作用是什么?
当map生成的数据过大时，带宽就成了瓶颈，怎样精简压缩传给Reduce的数据，又不影响最终的结果呢。有一种方法就是使用Combiner，Combiner号称本地的Reduce，Reduce最终的输入，是Combiner的输出。
##  你们数据库怎么导入hive 的,有没有出现问题
在导入hive的时候，如果数据库中有blob或者text字段，会报错，解决方案在sqoop笔记中。在将数据由Oracle数据库导入到Hive时，发现带有clob字段的表的数据会错乱，出现一些字段全为NULL的空行。由于在项目中CLOB字段没有实际的分析用途，因此考虑将CLOB字段去掉。
## hdfs-site.xml的3个主要属性?
dfs.name.dir决定的是元数据存储的路径以及DFS的存储方式(磁盘或是远端)
dfs.data.dir决定的是数据存储的路径
fs.checkpoint.dir用于第二Namenode
## 下列哪项通常是集群的最主要瓶颈
磁盘 IO 
答案：C 磁盘 
首先集群的目的是为了节省成本，用廉价的 pc 机，取代小型机及大型机。小型机和大型机有什么特点？ 
1.cpu 处理能力强 
2.内存够大，所以集群的瓶颈不可能是 a 和 d 
3.如果是互联网有瓶颈，可以让集群搭建内网。每次写入数据都要通过网络（集群是内网），然后还要写入 3 份数据，所以 IO 就会打折扣。

## 关于 SecondaryNameNode 哪项是正确的？
它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间 
## mapreduce的原理?
MapReduce采用”分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个分节点共同完成，然后通过整合各个节点的中间结果， 
得到最终结果。简单地说，MapReduce就是”任务的分解与结果的汇总”。 
在Hadoop中，用于执行MapReduce任务的机器角色有两个：一个是JobTracker；另一个是TaskTracker，JobTracker是用于调度工作的，TaskTracker 
是用于执行工作的。一个Hadoop集群中只有一台JobTracker。 
在分布式计算中，MapReduce框架负责处理了并行编程中分布式存储、工作调度、负载均衡、容错均衡、容错处理以及网络通信等复杂问题，把处理 
过程高度抽象为两个函数：map和reduce，map负责把任务分解成多个任务，reduce负责把分解后多任务处理的结果汇总起来。 
需要注意的是，用MapReduce来处理的数据集（或任务）必须具备这样的特点：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都 
可以完全并行地进行处理。
## HDFS存储的机制?
### 写流程： 
client链接namenode存数据 
namenode记录一条数据位置信息（元数据），告诉client存哪。 
client用hdfs的api将数据块（默认是64M）存储到datanode上。 
datanode将数据水平备份。并且备份完将反馈client。 
client通知namenode存储块完毕。 
namenode将元数据同步到内存中。 
另一块循环上面的过程。
###  读流程
## 举一个简单的例子说明mapreduce是怎么来运行的 ?
MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。 
　　Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。 
Mapper任务的执行过程详解 
　　每个Mapper任务是一个Java进程，它会读取HDFS中的文件，解析成很多的键值对，经过我们覆盖的map方法处理后， 
转换为很多的键值对再输出。整个Mapper任务的处理过程又可以分为以下六个阶段： 
　　第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。默认情况下，输入片(InputSplit) 
的大小与数据块(Block)的大小是相同的。如果数据块(Block)的大小是默认值128MB，输入文件有两个，一个是32MB，一个是　172MB。那么小的文件是一个输入片，大文件会分为两个数据块，那么是两个输入片。一共产生三个输入片。每一个输入片由　一个Mapper进程处理。这里的三个输入片，会有三个Mapper进程处理。

　　第二阶段是对输入片中的记录按照一定的规则解析成键值对。有个默认规则是把每一行文本内容解析成键值对。“键”是每一　行的起始位置(单位是字节)，“值”是本行的文本内容。 
　　 
　　第三阶段是调用Mapper类中的map方法。第二阶段中解析出来的每一个键值对，调用一次map方法。如果有1000个键值对，就会　调用1000次map方法。每一次调用map方法会输出零个或者多个键值对。

　　第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。比较是基于键进行的。比如我们的键表示省份(如北京、上海、　山东等)，那么就可以按照不同省份进行分区，同一个省份的键值对划分到一个区中。默认是只有一个区。分区的数量就是Reducer　任务运行的数量。默认只有一个Reducer任务。 
第五阶段是对每个分区中的键值对进行排序。首先，按照键进行排序，对于键相同的键值对，按照值进行排序。比如三个键值　对<2,2>、<1,3>、<2,1>，键和值分别是整数。那么排序后的结果是<1,3>、<2,1>、<2,2>。如果有第六阶段，那么进入

第六阶段　如果没有，直接输出到本地的Linux文件中。　第六阶段是对数据进行归约处理，也就是reduce处理。键相等的键值对会调用一次reduce方法。经过这一阶段，数据量会减少。　归约后的数据输出到本地的linxu文件中。本阶段默认是没有的，需要用户自己增加这一阶段的代码。　Reducer任务的执行过程详解 
每个Reducer任务是一个java进程。Reducer任务接收Mapper任务的输出，归约处理后写入到HDFS中，可以分为三个阶段： 
第一阶段是Reducer任务会主动从Mapper任务复制其输出的键值对。Mapper任务可能会有很多，因此Reducer会复制多个Mapper的输出。 
第二阶段是把复制到Reducer本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。 
第三阶段是对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对。 
最后把这些输出的键值对写入到HDFS文件中。 
在整个MapReduce程序的开发过程中，我们最大的工作量是覆盖map函数和覆盖reduce函数。

## 了解hashMap 和hashTable吗介绍下，他们有什么区别。



## 为什么重写equals还要重写hashcode
因为equals比较的是内容是一致.但hashcode

## 说一下map的分类和常见的情况
 hashmap,hashtable,treemap,LinkedHashMap
* 根据键得到值，因此不允许键重复(重复了覆盖了),但允许值重复
### Hashmap 
是一个最常用的Map
* 它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的
* 最多只允许一条记录的键为Null;允许多条记录的值为 Null;
* HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致。
* 如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap
### Hashtable
Hashtable与 HashMap类似,它继承自Dictionary类,不同的是:它不允许记录的键或者值为空;
* 它支持线程的同步，即任一时刻只有一个线程能写Hashtable,因此也导致了 Hashtable在写入时会比较慢
### LinkedHashMap
是 HashMap 的一个子类，保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的.
也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比 HashMap 慢，不过有种情况例外，当 HashMap 容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap 慢，因为 LinkedHashMap 的遍历速度只和实际数据有关，和容量无关，而 HashMap 的遍历速度和他的容量有关
### TreeMap
实现 SortMap 接口,能够把它保存的记录根据键排序, 默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的

HashMap，链表法存储，entry[]数组，线程不安全，可能死锁 concurrentHashMap，segment数组，每个segent下维护一组entry[]数组，每个segment是一把锁，线程安全 LinkedHashMap

---

## Object若不重写hashCode()的话，hashCode()如何计算出来的？
hashcode采用的是



## spark

### 1. spark的有几种部署模式，每种模式特点？

#### 本地模式
本地模式分三类
* local：只启动一个executor
* local[k]: 启动k个executor
* local[*]：启动跟cpu数目相同的 executor

### cluster模式
cluster模式肯定就是运行很多机器上了，但是它又分为以下三种模式，区别在于谁去管理资源调度。（说白了，就好像后勤管家，哪里需要资源，后勤管家要负责调度这些资源）
#### standalone模式
分布式部署集群，自带完整的服务，资源管理和任务监控是Spark自己监控，这个模式也是其他模式的基础

#### Spark on yarn模式
分布式部署集群，资源和任务监控交给yarn管理
粗粒度资源分配方式，包含cluster和client运行模式
cluster 适合生产，driver运行在集群子节点，具有容错功能
client 适合调试，dirver运行在客户端

###  2. Spark技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？

#### Spark core
是其它组件的基础，spark的内核
主要包含：有向循环图、RDD、Lingage、Cache、broadcast等

#### SparkStreaming
是一个对实时数据流进行高通量、容错处理的流式处理系统
将流式计算分解成一系列短小的批处理作业

#### Spark sql：
能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行外部查询
#### MLBase
是Spark生态圈的一部分专注于机器学习，让机器学习的门槛更低
MLBase分为四部分：MLlib、MLI、ML Optimizer和MLRuntime。
#### GraphX
是Spark中用于图和图并行计算
#### spark有哪些组件
master：管理集群和节点，不参与计算。
worker：计算节点，进程本身不参与计算，和master汇报。
Driver：运行程序的main方法，创建spark context对象。
spark context：控制整个application的生命周期，包括dagsheduler和task scheduler等组件。
client：用户提交程序的入口。


*   https://blog.csdn.net/yirenboy/article/details/47441465