title: 大数据分享

date: 2020-05-11

tags: 日常总结
abstract: 大数据分享

---


## 开头语

```工欲善其事，必先利其器```
<!-- more -->
本次分享,是我在公司的第一次分享,我考虑后,将本次分享的主要内容分为了三大部块.先是针对相关基础组件分类介绍.再介绍下通过对这些组件进行组织配搭的大数据基础环境架构.再结合我的一些经历,为大家介绍下相关的应用与产品落地.


## 技术栈简介
* 数据采集
* 数据存储
* 数据治理(清洗&处理)
* 数据应用
* 产品落地



我又根据不同组件的特性将他们分
* 采集类
* 存储类
* 计算处理类
* 传输类
* 管理类 
* 其它类

下面开始具体介绍

## 采集类

数据源:
* 日志
* 业务数据
* 公网数据(爬虫)
* 文本数据
* 出行数据(gps,手机定位等)

![2019-04-15-10-36-53](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-10-36-53.png)

* sqoop flume crawler datax kettle  elk
1. Flume(水槽) 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单,可拓展
2. Sqoop是一个在结构化数据和Hadoop之间进行批量数据迁移的工具，结构化数据可以是Mysql、Oracle等RDBMS。Sqoop底层用MapReduce程序实现抽取、转换、加载，MapReduce天生的特性保证了并行化和高容错率，而且相比Kettle等传统ETL工具，任务跑在Hadoop集群上，减少了ETL服务器资源的使用情况。在特定场景下，抽取过程会有很大的性能提升。
3. crawler , jsoup ,httpclient, nutch 等.
4. elk  集中式日志系统 ELK 协议栈详解
![2019-04-15-10-11-16](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-10-11-16.png)
---

## 存储类
* hdfs
* hbase
* hive
* mongdb
* redis
* RDBMS

### hdfs
    * 分布式文件存储系统
    * 提供了高可靠性、高扩展性和高吞吐率的数据存储服务
    * hdfs典型结构：物理结构+逻辑结构
    
    * 文件线性切割成Block：偏移量（offset）
    * Block分散存储在集群节点中
    * 单一文件Block大小一致，文件与文件可以不一致
    * Block可以设置副本数，副本分散在不同的节点中
    * 副本数不要超过节点数量
    * 文件上传可以设置Block大小和副本数
    * 已上传的文件Block副本数可以调整，大小不变
    * 只支持一次写入多次读取，同一时刻只有一个写入者
    * 只能追加，不能修改

![2019-04-15-11-12-40](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-11-12-40.png)

### hbase
Base是一个构建在HDFS上的分布式列存储系统；
Base是基于Google BigTable模型开发的，典型的key/value系统；
Base是Apache Hadoop生态系统中的重要一员，主要用于海量结构化数据存储；

大：一个表可以有数十亿行，上百万列；无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列；面向列：面向列（族）的存储和权限控制，列（族）独立检索；稀疏：空（null）列并不占用存储空间，表可以设计的非常稀疏；数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳；数据类型单一：Hbase中的数据都是字符串，没有类型
#### openTSDB
基于Hbase的分布式的，可伸缩的时间序列数据库。
主要用途，就是做监控系统；譬如收集大规模集群（包括网络设备、操作系统、应用程序）的监控数据并进行存储，查询。
![2019-04-15-11-27-46](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-11-27-46.png)

#### solr & Phoenix

二级索引

### hive 
ive 是一个基于 Hadoop 文件系统之上的数据仓库架构。它可以将结构化的数据文件映射为一张数据库表，并提供简单的 sql 查询功能。还可以将 sql 语句转换为 MapReduce 任务运行。
底部计算引擎还可以用用Tez, spark等.
![2019-04-15-11-36-43](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-11-36-43.png)

##### Impala
Impala是Cloudera公司推出，提供对HDFS、Hbase数据的高性能、低延迟的交互式SQL查询功能。
* 基于Hive使用内存计算，兼顾数据仓库、具有实时、批处理、多并发等优点
* 对内存依赖大,稳定性不如hive

相比hive数据仓库,impala针对的量级相关少些,但会有效率的提升.但一般来讲,数据仓库一类需求对时间上的要要求一般不会太高,所以常规方式一般就符合大多数需求.

## 计算处理类
* mapreduce
* mapreduce on oozie ,on tez 
* spark 
* flink

### mapreduce 
Mapreduce是一个计算框架，既然是做计算的框架，那么表现形式就是有个输入（input），mapreduce操作这个输（input），通过本身定义好的计算模型，得到一个输出（output），这个输出就是我们所需要的结果。我们要学习的就是这个计算模型的运行规则。在运行一个mapreduce计算任务时候，任务过程被分为两个阶段：map阶段和reduce阶段，每个阶段都是用键值对（key/value）作为输入（input）和输出（output）。而程序员要做的就是定义好这两个阶段的函数：map函数和reduce函数。

分布式计算；
移动计算而不移动数据。
![2019-04-15-11-59-56](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-15-11-59-56.png)

### spark
相比一二代计算引擎,在兼并了一二代的特色之外,还引放了流计算这一能力,还丰富了计算函数.
其中比较有代表性的主要就是spark&storm.
也就是说这代计算引擎兼具无边界数据与有边界数据同样的处理能力.同时还具有DAG特性.
这里主要介绍spark

spark主要组成有以下
* spark-core
* spark-streaming
* spark-sql
* spark-mlib
* spark-graphX。

spark-core是一个提供内存计算的框架,其他的四大框架都是基于spark core上进行计算的,所以没有spark core,其他的框架是浮云.
spark-core的主要内容就是对RDD的操作
RDD的创建 ->RDD的转换 ->RDD的缓存 ->RDD的行动 ->RDD的输出

spark-streaming中使用离散化流（discretized stream）作为抽象的表示，叫做DStream。它是随时间推移而收集数据的序列，每个时间段收集到的数据在DStream内部以一个RDD的形式存在。DStream支持从kafka，flume,hdfs,s3等获取输入。DStream也支持两种操作，即转化操作和输出操作


spark-sql
Spark SQL 提供了查询结构化数据及计算结果等信息的接口.
查询结果以 Datasets and DataFrames 形式返回

...

### flink/blink

略

## 传输类
### kafka
Kafka是分布式发布-订阅消息系统,一个分布式的，可划分的，冗余备份的持久性的日志服务。它主要用于处理活跃的流式数据。日常中常与spark-streaming结合实用,为其提供无边界数据

![2019-04-16-15-06-25](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-16-15-06-25.png)

## 管理类 Hue cloudera-manager
ue与cm 都是由cloudera提供,后面cloudera将hue开源给了apache.如果基础集群环境是采用的是开源自主搭建,可考虑引入hue.另一些大数据服务公司,有集成打包自己的一些大数据产品,如cdh等.但这些服务收费,涉及到成本问题.所以如何选用,需要相关斟酌.

## 其它类 zookeeper ,yarn等
zookeeper在集中基础环境中主要作为配置分享中心,与kafka,hbase等组件集成.yarn则作为资源管理组件,可以与mapreduce ,spark等集成

## 各类组件架构
以上,已经大致介绍了各类工具,基本了解了相应的特性和使用场景,而根据它们的特性,进行合理的配备,架构,从而实现一个功能全面,稳定的大数据环境.

于我个人经历与平时了解来讲,一般的架构主要如下
![2019-04-17-09-23-07](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-17-09-23-07.png)
另:
![2019-04-16-10-42-08](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-16-10-42-08.png)


总得来说,各类组件供选型一般来讲都不是单一的.所以,我们的大数据环境各部份组件都是插销式可插拔的.所以不同公司可能不一而同,具体看自身需求和实际情况.比如上图中的storm流式计算模块,就可以替换成spark-streaming等.

通过对上图的架构的拆解,再组合,可能还会有以下组织架构.

数据仓库
可以理解为上图中间部份.作为一个数据集市的存在,算作数据中心的一部份.

* ODS：是数据仓库第一层数据，直接从原始数据过来的，经过简单地处理，比喻：字段体重的数据为175cm等数据。
* DW*：这个是数据仓库的第二层数据，DWD和DWS很多情况下是并列存在的，这一层储存经过处理后的标准数据，比喻订单、用户、页面点击流量等数据。
* ADS：这个是数据仓库的最后一层数据，为应用层数据，直接可以给业务人员使用。
![2019-04-16-11-01-33](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-16-11-01-33.png)

星型模型

星型模型中有两个重要的概念：事实表和维度表。
事实表：一些主键ID的集合，没有存放任何实际的内容
维度表：存放详细的数据信息，有唯一的主键ID。如上面的关键词表、用户表等等。
![2019-04-16-11-04-52](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-16-11-04-52.png)

 数据中心:
概念相对更大一些,可能即作为具体平台产品集合,也可能是一个团队行政划分.总得来说,是如
* 大数据基础平台
* 数据仓库
* DMP平台
* 相关应用平台如推荐系统,报表系统,可视化平台等.


数据中台:
这个是由阿里于15年率先提出.主导思想是大中台,小前台.这块暂无特别明确的解释说法,但现在也有不少公司效仿.我个人从它的主导思想"大中台,小前台"的理解是,这个可能是体量更大,壁垒更少的一个数据集成体.比如阿里系的旗下公司,数据流都会归集到中台,同时阿里系下的公司也能获得不仅自己公司数据中心归集的数据反馈,还能获得阿里中台整合后流出的反馈数据.


## 应用落地
### 公共服务
* 交通出行
![2019-04-16-16-15-42](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-16-16-15-42.png)
* 智慧城市
* ...

### 产品应用
* 用户画像
* 征信模型
* 推荐系统
* 精确营销
* 前沿科学(无人驾驶,人工智能,AR等)


## 结语
以上,就是我今天分享的主要内容.今天的主题是"器",但对这些工具的讲解浅尝辄止,在实际的开发实战中涉及的情况是更为复杂,需要掌握的内容更多,深度也更深.我这里主要是想抛砖引玉,为大家提供一点自己的理解,若能有所帮助,不胜荣幸.

另外,工具始终是工具,菜刀再利也要厨子好,才能做好菜.所以如何利用这些工具,与我们的业务结合,实现我们想要的价值,这是我一直在探索的,也愿与各位同仁一同前行.

附上图中涉及到的技术栈

![2019-04-17-09-09-00](http://rgr3ifyzo.sabkt.gdipper.com/2019-04-17-09-09-00.png)






